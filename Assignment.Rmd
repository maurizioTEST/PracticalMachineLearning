---
title: "Assignment 2 Practical Machine Learning"
output: html_document
---
## Loading data and package

We start by loading the training and test data, the caret package and by 
checking data dimensions
```{r}
library(caret)
testing=read.csv("pml-testing.csv")
training=read.csv("pml-training.csv")
dim(training)#compute the dimensions of the training set
dim(testing)#compute the dimensions of the test set
```

## Exploratory analysis
We first look for the presence of not assigned data both in the training and in the test set
```{r}
trainmiss=c()
for (i in 1:ncol(training))
 trainmiss[i]=length(which(is.na(training[,i])))
trainmiss#number of missing data for each variable
```
Also 
```{r}
testmiss=c()
for (i in 1:ncol(testing))
  testmiss[i]=length(which(is.na(testing[,i])))
testmiss
```
We notice here that for a lot variables we miss the vast majority of the data (19216 out of 19622). in the training set. 
We  drop such columns as well the column for which no test result is given.
```{r}
col=which(trainmiss>0)
training[,-col]->training
testing[,-col]->testing
colte=testmiss[-col]
col=which(colte>0)
training[,-col]->trainingR
testing[,-col]->testingR
```
So we reduced to the variables that are present both in the training set and in the test set!
Also all variables show some variability
```{r}
str(trainingR) 
nsv <- nearZeroVar(trainingR,saveMetrics=TRUE)
nsv
```
We drop  also the variables in columnn 1 (index) and 2 (name) that are clearly irrelevant and the cvtd_timestamp column 5.
```{r}
c(1,2,5)->drop
trainingR[,-drop]->trainingR
testingR[,-drop]->testingR
```
## Data splitting in training and test set
We partition now the data  into training and test set (we use a small fraction of the dataset in the training set to speed up computations)
```{r}
set.seed(10)
inTrain <- createDataPartition(y=trainingR$classe,  p=0.1, list=FALSE)
train=trainingR[inTrain,]
test=trainingR[-inTrain,]
dim(train)
```
Now we create the model and select the most important variables
```{r}
model <- train( classe ~ .,method="rf",data=train,prox=TRUE)
selected=rownames(varImp(model)[[1]])[order(-varImp(model)[[1]][,1])][1:10]
selected      
```
Now we check how the model fit the training and test set in particular getting the out of sample error
```{r}
pred=predict (model, train[,-ncol(train)], na.action = na.pass)
table(pred,train$classe)
pred=predict (model, test[,-ncol(training)], na.action = na.pass)
table(pred,test$classe)
predictions <- predict(model,newdata=test)
confusionMatrix(predictions,test[,"classe"])
```
Thus getting an accuracy of 0.9818
Let us reduce the model using only the selected 10 most important variables, again by using just a small ratio of the data (to speed computations)
```{r}
set.seed(23)
inTrain <- createDataPartition(y=trainingR$classe,  p=0.2, list=FALSE)
train_sel=trainingR[inTrain,c(selected,"classe")]
test_sel=trainingR[-inTrain,c(selected,"classe")]
model_sel <- train(classe ~ .,method="rf",data=train_sel,prox=TRUE)
predictions <- predict(model_sel,newdata=train_sel)
confusionMatrix(predictions,train_sel$classe)
predictions <- predict(model_sel,newdata=test_sel)
confusionMatrix(predictions,test_sel$classe)
```
Achieving here an even better  accuracy of 0.9939.
